{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16b1ed83",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8626793",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "from src.data_process import DataStorage, FeaturesGenerator\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "from codecarbon import EmissionsTracker\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f01ac3",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5908a698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se leen y se preprocesan los datos\n",
    "data_storage = DataStorage()\n",
    "features_generator = FeaturesGenerator(data_storage=data_storage)\n",
    "train_data = features_generator.generate_features(data_storage.df_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb89c876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se definen parametros de preprocesado\n",
    "preprocessing_params = {\n",
    "    \"n_features\": 60,\n",
    "    \"is_holiday\": True\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cb7fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea la matriz de correlación\n",
    "correlation_matrix = train_data.corr()\n",
    "\n",
    "# Se ordenan las columnas en función del valor absoluto de la correlación.\n",
    "target_column = 'target'\n",
    "correlation_with_target = correlation_matrix[target_column].abs().sort_values(ascending=False)\n",
    "\n",
    "# Se seleccionan las N features más correlacionadas sin incluir el target\n",
    "top_n_features = correlation_with_target[1:preprocessing_params[\"n_features\"]]  \n",
    "\n",
    "print(\"Top correlated features with\", target_column)\n",
    "print(top_n_features.index.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3086571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se combiana la columna objetivo con las columnas más correlacionadas en un nuevo DataFrame.\n",
    "selected_features_df = train_data[top_n_features.index.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6253c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = selected_features_df\n",
    "y = train_data[target_column]\n",
    "\n",
    "# Se crea un Split para series temporales\n",
    "tsvc = TimeSeriesSplit(n_splits=6)\n",
    "# Se definen los parametros\n",
    "params = {\n",
    "    \"learning_rate\" : .1,\n",
    "    \"max_depth\" : 10,\n",
    "    \"n_estimators\" : 500\n",
    "}\n",
    "# Se ejecuta la validación cruzada para series temporales\n",
    "scores = cross_val_score(XGBRegressor(**params,enable_categorical=True,), X,y,cv=tsvc, scoring=\"neg_mean_absolute_error\")\n",
    "\n",
    "# Se hace la media de las metricas y se multiplica por -1 porque la librería tiene implementada la metrica en negativo: neg_mean_absolute_error\n",
    "mean_score = np.mean(scores)*-1\n",
    "print(f\"Mean_score: {mean_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3be1139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se inicializa el tracker de emisiones\n",
    "tracker = EmissionsTracker()\n",
    "# Se define el modelo en cuestión con los parámetros\n",
    "my_model = XGBRegressor(**params,enable_categorical=True,)\n",
    "# Se inicializa el tracker y se entrena\n",
    "tracker.start()\n",
    "my_model.fit(X, y)\n",
    "emissions = tracker.stop()\n",
    "print(f\"Emissions:{emissions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2826b62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se cargan nuevos datos y se prerprocesan\n",
    "data_storage.update_with_new_data(\n",
    "        df_new_client=pd.read_csv(\"data/example_test_files/client.csv\"),\n",
    "        df_new_gas_prices=pd.read_csv(\"data/example_test_files/gas_prices.csv\"),\n",
    "        df_new_electricity_prices=pd.read_csv(\"data/example_test_files/electricity_prices.csv\", parse_dates=[\"forecast_date\",\"origin_date\"]),\n",
    "        df_new_forecast_weather=pd.read_csv(\"data/example_test_files/forecast_weather.csv\", parse_dates=[\"origin_datetime\", \"forecast_datetime\"]),\n",
    "        df_new_historical_weather=pd.read_csv(\"data/example_test_files/historical_weather.csv\", parse_dates=[\"datetime\"]),\n",
    "        df_new_target=pd.read_csv(\"data/example_test_files/revealed_targets.csv\", parse_dates=[\"datetime\"])\n",
    "    )\n",
    "df_test = data_storage.preprocess_test(pd.read_csv(\"data/example_test_files/test.csv\",  parse_dates=[\"prediction_datetime\"]))\n",
    "df_test_features = features_generator.generate_features(df_test, has_target=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44deaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea una predicción\n",
    "predictions = my_model.predict(df_test_features[top_n_features.index.tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304fbebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "# Nos conectamos a nuestro servidor de MLFlow y se crea un nuevo experimento\n",
    "mlflow.set_tracking_uri(uri=MLFLOW_SERVER_URL)\n",
    "mlflow.set_experiment(\"Enefit-XGBoost\")\n",
    "\n",
    "# MLFlow en este momento no acepta la variables categóricas asi que se convierten estas variales a strings\n",
    "# para que se registren todas las features.\n",
    "X[[\"is_consumption\",\"product_type\",\"is_business\",\"county\",\"segment\"]] = X[[\"is_consumption\",\"product_type\",\"is_business\",\"county\",\"segment\"]].astype(str)\n",
    "signature = mlflow.models.infer_signature(X, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8467a090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se registra el experimento en MLFlow\n",
    "with mlflow.start_run():\n",
    "    # Se juntan los parametros de preprocesado con los de entrenamiento\n",
    "    mlflow.log_params(params | preprocessing_params)\n",
    "    mlflow.log_metric(\"mean_absolute_error\", mean_score)\n",
    "    # Se guardan también las emisiones\n",
    "    mlflow.log_metric(\"emissions\", emissions)\n",
    "    mlflow.set_tag(\"Basic XGBoost experiment\", \"First experiment\")\n",
    "    model_info = mlflow.xgboost.log_model(\n",
    "        xgb_model=my_model,\n",
    "        artifact_path=\"enefit_model\",\n",
    "        signature=signature,\n",
    "        input_example=X,\n",
    "        registered_model_name=\"enefit-xgboost-experiment\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
